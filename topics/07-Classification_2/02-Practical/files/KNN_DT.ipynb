{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ca38b4c5",
      "metadata": {},
      "source": [
        "# Classifying iris plants according to their measurements\n",
        "\n",
        "We use sklearn to classify the iris data we saw back in Week 1.\n",
        "\n",
        "The data is included in scikit-learn, so we can get it directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3a9c017",
      "metadata": {
        "tags": [
          "imports"
        ]
      },
      "outputs": [],
      "source": [
        "import itertools, os, re, string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn import neighbors, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from IPython.display import display, Image\n",
        "import pydotplus as pdp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "421d549b",
      "metadata": {
        "tags": [
          "load"
        ]
      },
      "outputs": [],
      "source": [
        "iris = datasets.load_iris()\n",
        "print(dir(iris)) # Note that it is not a dataframe, more a generalised data object\n",
        "print(iris.feature_names)\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# create the model\n",
        "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# fit the model\n",
        "knn.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d80dc9d3",
      "metadata": {},
      "source": [
        "With knn, you can determine membership probabilities for each of the 3 labels. As you can see, the predict() function just picks the most likely label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47b29d80",
      "metadata": {
        "tags": [
          "knn_predict"
        ]
      },
      "outputs": [],
      "source": [
        "# What kind of iris has 3cm x 5cm sepal and 4cm x 2cm petal?\n",
        "# call the \"predict\" method:\n",
        "result = knn.predict([[3, 5, 4, 2],])\n",
        "\n",
        "print(iris.target_names[result])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1220199",
      "metadata": {
        "tags": [
          "knn_predictProb"
        ]
      },
      "outputs": [],
      "source": [
        "knn.predict_proba([[3, 5, 4, 2],]) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9520177",
      "metadata": {},
      "source": [
        "Make sure the directory exists beforehand to store the generated plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09fff32c",
      "metadata": {
        "lines_to_next_cell": 1,
        "tags": [
          "ensureOutput"
        ]
      },
      "outputs": [],
      "source": [
        "picDir = \"output/pics\"\n",
        "if not os.path.exists(picDir):\n",
        "  os.makedirs(picDir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7396d803",
      "metadata": {},
      "source": [
        "The following utility class plots a coloured mesh showing regions where\n",
        "a label would be chosen, overlaid with the training and test points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4108511",
      "metadata": {
        "lines_to_next_cell": 1,
        "tags": [
          "plot_2d_class"
        ]
      },
      "outputs": [],
      "source": [
        "def plot_2d_class(X, y, nTrain, model, plotTitle, fileTitle, cmap_area, cmap_pts):\n",
        "  predNames=list(X.columns)\n",
        "  c1 = predNames[:1] # first of 2\n",
        "  c2 = predNames[-1:] # last of 2\n",
        "  x_min, x_max = X[c1].min() - .1, X[c1].max() + .1\n",
        "  y_min, y_max = X[c2].min() - .1, X[c2].max() + .1\n",
        "  xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
        "                       np.linspace(y_min, y_max, 100))\n",
        "  # Wrap numpy array in a dataframe, to avoid \"UserWarning: X does not have valid feature names, but [..]Classifier was fitted with feature names\"\n",
        "  Xgrid = pd.DataFrame(np.c_[xx.ravel(), yy.ravel()], columns=[c1[0], c2[0]])\n",
        "  Z = model.predict(Xgrid)\n",
        "\n",
        "  # Add the areas coloured by the fit\n",
        "  Z = Z.reshape(xx.shape)\n",
        "  \n",
        "  fig, ax = plt.subplots()\n",
        "  ax.pcolormesh(xx, yy, Z, cmap=cmap_area, shading='auto')\n",
        "\n",
        "  x1 = list(itertools.chain.from_iterable(X[c1].values)) # https://stackoverflow.com/a/11264799\n",
        "  x2 = list(itertools.chain.from_iterable(X[c2].values))\n",
        "\n",
        "  # Plot the points with colours in the same colour segment as the area\n",
        "  ax.scatter(x1[:nTrain], x2[:nTrain], c=y[:nTrain], cmap=cmap_pts) # training data\n",
        "  ax.scatter(x1[nTrain:], x2[nTrain:], c=y[nTrain:], cmap=cmap_pts, edgecolors=\"black\") # test data\n",
        "\n",
        "  ax.set_title(plotTitle)\n",
        "  ax.set_xlabel(c1[0])\n",
        "  ax.set_ylabel(c2[0])\n",
        "  fig.tight_layout()\n",
        "  fig.savefig(fileTitle,bbox_inches='tight')\n",
        "  #pl.close(fig) # See https://stackoverflow.com/a/37336028/1988855"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7728a551",
      "metadata": {},
      "source": [
        "Define a function that prepares 2-feature models for display, then calls `plot_2d_class` to display them in context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfff39d6",
      "metadata": {
        "lines_to_next_cell": 1,
        "tags": [
          "twoFeatureModels"
        ]
      },
      "outputs": [],
      "source": [
        "def dispTwoFeatureModels(predNames, df, pattern, model, modelType, hpName, hp, cmap_light, cmap_bold):\n",
        "  for twoCols in itertools.combinations(predNames, 2): # https://stackoverflow.com/a/374645\n",
        "    X = df[list(twoCols)]  # we only take two features at a time\n",
        "    colNames = X.columns\n",
        "    c1 = colNames[:1][0] # first of 2\n",
        "    c2 = colNames[-1:][0] # last of 2\n",
        "    c1 = pattern.sub(\"\",c1.title()) # Make titlecase, then remove non-alphanumeric characters\n",
        "    c2 = pattern.sub(\"\",c2.title())\n",
        "    model.fit(X, y)\n",
        "    plotTitle = f\"{hpName} = {hp} {modelType} fit to the Iris dataset\"\n",
        "    fileTitle = picDir + f\"/{hpName}_{hp}_{modelType}_Iris_{c1}_{c2}.pdf\"\n",
        "    print(\"Plotting file %s\" % (fileTitle))\n",
        "    plot_2d_class(X, y, nTrain, knn, plotTitle, fileTitle, cmap_light, cmap_bold)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cd4ab3f",
      "metadata": {},
      "source": [
        "Remember: the label (0,1,2) maps to setosa, versicolor and virginica. Therefore, the probability that it is setosa, versicolor or virginica is 0, 0.8 and 0.3, respectively. Clearly versicolor is chosen!\n",
        "\n",
        "In the next block of code, we take each pair of predictors from the four available in the Iris data set, and use the k-nearest-neighbour algorithm with k=3,5,7. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe3a45e3",
      "metadata": {
        "tags": [
          "fitsWithPlots"
        ]
      },
      "outputs": [],
      "source": [
        "# the following import is no longer needed, because plot_2d_class has been added above\n",
        "#from plotSupp import plot_2d_class\n",
        "\n",
        "# Create color maps for 3-class classification problem, as with iris\n",
        "cmap_light = ListedColormap(['#FFDDDD', '#DDFFDD', '#DDDDFF'])\n",
        "cmap_bold = ListedColormap(['#FF2222', '#22FF22', '#8888FF'])\n",
        "\n",
        "#predNames = list(iris.data) # https://stackoverflow.com/a/19483025, except iris.data is an array, not a dataframe\n",
        "predNames = iris.feature_names\n",
        "df=pd.DataFrame(iris.data, columns=predNames)\n",
        "nTrain = df.shape[0]\n",
        "y = iris.target\n",
        "pattern = re.compile('[\\W_]+', re.UNICODE) # https://stackoverflow.com/a/1277047\n",
        "\n",
        "for neighborCnt in range(3,8,2): # from 3 to a maximum of 8, in steps of 2, so 3,5,7\n",
        "  knn = neighbors.KNeighborsClassifier(n_neighbors=neighborCnt)\n",
        "  dispTwoFeatureModels(predNames, df, pattern, model=knn, modelType=\"KNN\", hpName=\"k\", hp=neighborCnt, cmap_light=cmap_light, cmap_bold=cmap_bold)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "950f6775",
      "metadata": {},
      "source": [
        "## Model Validation\n",
        "\n",
        "The k-nearest-neighbours classification \"model\" should be validated. Clearly, the parameter $k$ is critical to its performance. Generally, smaller values of $k$ fit the training set more accurately (less bias) but generalise less well to test data (more variance). The opposite applies to larger values of $k$.\n",
        "\n",
        "With $k$ set to its minimum value ($k = 1$), it fits the training set exactly and the confusion matrix is optimal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "677f8570",
      "metadata": {
        "tags": [
          "kequals1"
        ]
      },
      "outputs": [],
      "source": [
        "X, y = iris.data, iris.target\n",
        "knn1 = KNeighborsClassifier(n_neighbors=1)\n",
        "knn1.fit(X, y)\n",
        "y_pred1 = knn1.predict(X)\n",
        "print(np.all(y == y_pred1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80f04923",
      "metadata": {},
      "source": [
        "The *confusion matrix* highlights where classification differences arise, as these occur on the off-diagognal elements of the matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "797d68f9",
      "metadata": {
        "tags": [
          "kequals1metrics"
        ]
      },
      "outputs": [],
      "source": [
        "print(accuracy_score(y, y_pred1))\n",
        "print(confusion_matrix(y, y_pred1))\n",
        "print(classification_report(y, y_pred1, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db6c0ee2",
      "metadata": {
        "tags": [
          "metricsDiscussion"
        ]
      },
      "source": [
        "All 50 training samples for each class are identified correctly, as expected when $k = 1$ (accuracy score is 1, off-diagonal terms are 0, the classification report (relative to the trsining set) is \"too good to be true\"...\n",
        "\n",
        "Note:\n",
        "\n",
        "1. The _Recall_ of the $i^{\\mbox{th}}$ predictor is $R_i \\equiv c_{ii} / \\sum_j c_{ij}$, which is the ratio of the $i^{\\mbox{th}}$ diagonal element to the sum of the elements of the confusion matrix $C = \\{c_{ij}\\}$ in that _column_.\n",
        "2. The _Precision_ of the $j^{\\mbox{th}}$ predictor is $P_j \\equiv c_{jj} / \\sum_i c_{ij}$, which is the ratio of the $j^{\\mbox{th}}$ diagonal element to the sum of the elements of the confusion matrix $C = \\{c_{ij}\\}$ in that _row_.\n",
        "3. $F_1$-score is defined as $F_1 = 2\\frac{R_i P_i}{R_i + P_i}$.\n",
        "\n",
        "To test how the model generalizes to the training set, we hold back some of the training data by splitting the training data into a _training set_ and a _testing set_. We hold back 20% and stratify based on the data labels $y$, so each of the row counts in the confusion matrix should be $0.2 * 50 = 10$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7179369",
      "metadata": {
        "tags": [
          "split"
        ]
      },
      "outputs": [],
      "source": [
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "knn1.fit(Xtrain, ytrain)\n",
        "ypred1s = knn1.predict(Xtest)\n",
        "print(accuracy_score(ytest, ypred1s))\n",
        "print(confusion_matrix(ytest, ypred1s))\n",
        "print(classification_report(ytest, ypred1s, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "776821d3",
      "metadata": {},
      "source": [
        "Note the confusion (off-diagonal nonzero elements) between Iris species 2 and species 3. For comparison, we look at the confusion matrix when $k = 3$. Firstly, we try with all the training data (not holding any observations back for a test set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1104fe2",
      "metadata": {
        "tags": [
          "kEquals3"
        ]
      },
      "outputs": [],
      "source": [
        "knn3 = KNeighborsClassifier(n_neighbors=3)\n",
        "knn3.fit(X, y)\n",
        "y_pred3 = knn3.predict(X)\n",
        "print(accuracy_score(y, y_pred3))\n",
        "print(confusion_matrix(y, y_pred3))\n",
        "print(classification_report(y, y_pred3, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e101a49d",
      "metadata": {},
      "source": [
        "Note that 6 observations (3 each of species 2 and 3) are not classified the same as the human experts. However, this might also indicate something interesting about those observations. They could be outliers (not classified correctly) but, at the very least, they are extreme observations.\n",
        "\n",
        "Now we try holding back 20% of the training set for use as test observations, leaving 80% of the training data to train the classifier. We then look at what happens to the confusion matrix. Note that sampling the data like this could result in *better* relative performance, depending on what happens to the 6 problematic observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea55b11a",
      "metadata": {
        "tags": [
          "kEquals3metrics"
        ]
      },
      "outputs": [],
      "source": [
        "knn3.fit(Xtrain, ytrain)\n",
        "ypred3s = knn3.predict(Xtest)\n",
        "print(accuracy_score(ytest, ypred3s))\n",
        "print(confusion_matrix(ytest, ypred3s))\n",
        "print(classification_report(ytest, ypred3s, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a2315f5",
      "metadata": {},
      "source": [
        "Now we try a Decision Tree Classifier from sklearn on the same Iris data. The same interface is used as the k-nearest-networks classifier.\n",
        "\n",
        "Again, we separate the data into training and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ebf2472",
      "metadata": {
        "tags": [
          "fitDT"
        ]
      },
      "outputs": [],
      "source": [
        "# Derive Xtrain2, which is the \n",
        "XtrainDf = pd.DataFrame(data=Xtrain, columns=predNames)\n",
        "c1 = 'petal length (cm)'\n",
        "c2 = 'petal width (cm)'\n",
        "colNames = [c1, c2]\n",
        "Xtrain2 = XtrainDf[colNames]\n",
        "nTrain = Xtrain2.shape[0]\n",
        "\n",
        "XtestDf = pd.DataFrame(data=Xtest, columns=predNames)\n",
        "Xtest2 = XtestDf[colNames]\n",
        "Xcombined2 = pd.concat([Xtrain2, Xtest2])\n",
        "ycombined = np.hstack((ytrain, ytest))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b737f72",
      "metadata": {},
      "source": [
        "We also look at comparing different decision trees to the `PetalWidth` $\\times$ `PetalLength` data, based on the following conditions\n",
        "\n",
        "1. maximum tree depth (2,3,4,5)\n",
        "2. choice of tree impurity algorithm (`gini` or `entropy`)\n",
        "\n",
        "which is 8 combinations in all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb63e789",
      "metadata": {
        "tags": [
          "variedDT"
        ]
      },
      "outputs": [],
      "source": [
        "c1 = pattern.sub(\"\",c1.title()) # Make titlecase, then remove non-alphanumeric characters\n",
        "c2 = pattern.sub(\"\",c2.title())\n",
        "\n",
        "for treeDepth in range(2,6):\n",
        "  for criterion in [\"gini\",\"entropy\"]:\n",
        "    tree2 = DecisionTreeClassifier(criterion=criterion, max_depth=treeDepth, random_state=0)\n",
        "\n",
        "    tree2.fit(Xtrain2, ytrain)\n",
        "\n",
        "    plotTitle = \"depth = %i %s %s fit to the %s dataset\" % (treeDepth, criterion, \"DT\", \"Iris\")\n",
        "    fileTitle = picDir + \"/depth_%i_%s_%s_%s_%s_%s.pdf\" % (treeDepth, criterion, \"DT\", \"Iris\", c1, c2)\n",
        "\n",
        "    print(\"Plotting \"+fileTitle)\n",
        "    plot_2d_class(Xcombined2, ycombined, nTrain, tree2, plotTitle, fileTitle, cmap_light, cmap_bold)\n",
        "\n",
        "    ytree2 = tree2.predict(Xtest2)\n",
        "    print(accuracy_score(ytest, ytree2))\n",
        "    print(confusion_matrix(ytest, ytree2))\n",
        "    print(classification_report(ytest, ytree2, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69516eeb",
      "metadata": {},
      "source": [
        "Previous decision trees were based on just two predictors (`PetalWidth` and `PetalLength`) as this made visualisation easier. However, if we include all 4 predictors, we see that the fit can improve (score improves to 0.97 from 0.93)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85d29d93",
      "metadata": {
        "tags": [
          "entropyDT"
        ]
      },
      "outputs": [],
      "source": [
        "criterion = \"entropy\"\n",
        "treeDepth = 5\n",
        "tree = DecisionTreeClassifier(criterion=criterion, max_depth=treeDepth, random_state=0)\n",
        "tree.fit(Xtrain, ytrain)\n",
        "y_treeTest = tree.predict(Xtest)\n",
        "print(accuracy_score(ytest, y_treeTest))\n",
        "print(confusion_matrix(ytest, y_treeTest))\n",
        "print(classification_report(ytest, y_treeTest, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4f29059",
      "metadata": {
        "tags": [
          "visualiseDT"
        ]
      },
      "source": [
        "One of the main advantages of decision trees is the fact that they provide easily interpreted models for prediction. Indeed, the rules encoded in the tree can help to understand how the predictors combine and contribute to explaining the classification. As such, decision trees are often described as _white box_, where other algorithms (in particular, neural networks) are best seen as _black box_.\n",
        "\n",
        "To aid interpretation, `scikit-learn` can output the model in a graph description language such as [dot](https://www.graphviz.org/pdf/dotguide.pdf) using the `export_graphviz` method. If you wish, you can export the `dot` file and process it using tools, both command line such as [dotty](https://www.graphviz.org/pdf/dottyguide.pdf) and more general tools such as those listed [here](https://en.wikipedia.org/wiki/Graphviz). However, it is probably more convenient to use a `dot` postprocessor (`pydotplus`) directly from within the notebook to create an object that can be displayed in the notebook, or saved to a file as below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ec23734",
      "metadata": {
        "tags": [
          "visualiseDTcode"
        ]
      },
      "outputs": [],
      "source": [
        "# See https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\n",
        "dot_data = export_graphviz(\n",
        "    tree, \n",
        "    out_file=None,\n",
        "    feature_names=predNames,\n",
        "    class_names=['setosa', 'versicolor', 'virginica'],  \n",
        "    filled=True,\n",
        "    rounded=True)\n",
        "\n",
        "# Write dot_data to file, for optional postprocessing\n",
        "with open(picDir+\"/tree.dot\",\"w+\") as f:\n",
        "  f.writelines(dot_data)\n",
        "\n",
        "graph = pdp.graph_from_dot_data(dot_data)\n",
        "# create a PNG from the graph and display it in the notebook\n",
        "display(Image(graph.create_png()))\n",
        "graph.write_pdf(picDir+\"/tree.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e14d7c0",
      "metadata": {
        "tags": [
          "visualiseDTdiscussion"
        ]
      },
      "source": [
        "The nodes in the tree a coloured according to their function and impurity. The root is white, reflecting the fact that it has the highest impurity (mix of lables). The _setosa_ instances are releatively easily identified, because they share the condition that their `PetalWidth < 0.8cm`. The remaining 80 instances are then split on `PetalLength < 4.95cm`. While this improves the entropy (the child nodes have entropy 0.446 and 0.179), each of them requires further recursive splitiing. Also note that predictors such as `PetalLength` can reappear in further nodes, though the split is on a different value of the predictor (5.05cm instead of 4.95cm).\n",
        "\n",
        "The terminal nodes (leaves) are all pure, with 40, 37, 39, 3 and 1 nodes in each."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
