{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "491ed6f8",
      "metadata": {
        "tags": [
          "overview"
        ]
      },
      "source": [
        "# Visualise the sounds of letters spoken by 30 speakers\n",
        "\n",
        "The isolet1 dataset contains summarised audio data, collected \n",
        "from 30 speakers, each of whom speaks each letter of the alphabet twice.\n",
        "The data summarises the raw audio waveforms as 617 real-valued\n",
        "numbers.\n",
        "\n",
        "The data also indicates what letter was spoken by each participant.\n",
        "\n",
        "The data is intended for building classification models, but\n",
        "here we are using it to become familiar with dimensionality\n",
        "reduction techniques (PCA, t-SNE and UMAP).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3767c4f8",
      "metadata": {
        "incorrectly_encoded_metadata": "tags=[preparingTheData\"]"
      },
      "source": [
        "## Preparing the data for visualisation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c9561fb",
      "metadata": {
        "tags": [
          "importsM"
        ]
      },
      "source": [
        "First import the necessary library modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3047313b",
      "metadata": {
        "lines_to_next_cell": 1,
        "tags": [
          "imports"
        ]
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "# Might need to install umap first using conda install conda-forge::umap-learn\n",
        "# In Feb 2025 I discovered a version incompatibility...\n",
        "# umap uses an older form of numpy constants.\n",
        "# Unfortunately, since numpy 2.0, many older ways of referring to constants have been removed.\n",
        "# The developers of umap have not updated their code to use the new way.\n",
        "# I found that creating a python 3.11 environment in conda, and installing numpy and other packages there seemed to fix the problem.\n",
        "# That is, umap in a python 3.11 environment was able to work OK.\n",
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "import os\n",
        "if not os.path.exists('res'):\n",
        "    os.makedirs('res')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59a3d2bc",
      "metadata": {
        "tags": [
          "applyReducerM"
        ],
        "title": "markdown"
      },
      "outputs": [],
      "source": [
        "# Declare a function that can be used to apply the reducer and return the reduced dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bda2106e",
      "metadata": {
        "lines_to_next_cell": 1,
        "tags": [
          "applyReducer"
        ]
      },
      "outputs": [],
      "source": [
        "def applyReducer(reducer, df, colPrefix, n_components):\n",
        "  nd_reduced = reducer.fit_transform(df)\n",
        "  # Now derive df_reduced from the nd_reduced array, assigning suitable column names, using the default range index.\n",
        "  columns = [f'{colPrefix}{i}' for i in range(0,n_components)]\n",
        "  df_reduced = pd.DataFrame(data=nd_reduced, columns=columns)\n",
        "  display(df_reduced.head())\n",
        "  return df_reduced, reducer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a79d218",
      "metadata": {
        "tags": [
          "visualiseFunctionM"
        ],
        "title": "markdown"
      },
      "outputs": [],
      "source": [
        "# Declare a function that can be used to visualise the reduced dimensions of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaf3f879",
      "metadata": {
        "lines_to_next_cell": 1,
        "tags": [
          "visualiseFunction"
        ]
      },
      "outputs": [],
      "source": [
        "def visualiseReducedDim(df2, grouping, reducerType):\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111)\n",
        "  col = df2.columns\n",
        "  sns.scatterplot(\n",
        "    x=col[0], y=col[1],\n",
        "    hue=grouping,\n",
        "    palette=sns.color_palette(palette=\"hls\", n_colors=26),\n",
        "    data=df2,\n",
        "    legend=\"full\",\n",
        "    ax=ax\n",
        "  )\n",
        "  ax.set_title(f'{reducerType} visualisation')\n",
        "  ax.set_xlabel(col[0])\n",
        "  ax.set_ylabel(col[1])\n",
        "  fig.savefig(f'res/{reducerType}.pdf')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46dd94ca",
      "metadata": {
        "tags": [
          "readDataM"
        ]
      },
      "source": [
        "## Reading the data\n",
        "\n",
        "Read the data, check its size and view the first 10 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdd8799e",
      "metadata": {
        "tags": [
          "readData"
        ]
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/isolet1.csv', sep=',', header=None)\n",
        "m,n = df.shape\n",
        "print(f'Number of rows is {m} and number of columnes is {n}\\n')\n",
        "display(df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05a4904d",
      "metadata": {
        "tags": [
          "checkUniqueValuesM"
        ]
      },
      "source": [
        "Check that the first columns are the audio data and the last\n",
        "column is the index of each letter: 1 -> 'a', 2 -> 'b', etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "283ed86a",
      "metadata": {
        "tags": [
          "checkUniqueValues"
        ]
      },
      "outputs": [],
      "source": [
        "# Count unique values in each column using nunique()\n",
        "p = df.nunique()\n",
        "print(f\"Number of unique values in each column:\\n{p}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c96227ce",
      "metadata": {
        "tags": [
          "addFieldNamesM"
        ]
      },
      "source": [
        "The first row in the file contained data, not column names.\n",
        "So the dataframe column names are just integers starting at 0\n",
        "So we are going to generate new field names that start with 'f'\n",
        "and are followed by the index, left padded with zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbb84809",
      "metadata": {
        "tags": [
          "describeDataNames"
        ]
      },
      "outputs": [],
      "source": [
        "# Derive the column names, so that all but the last column has\n",
        "# a generated name and the last column is named 'letter'\n",
        "# See https://stackoverflow.com/a/339013/1988855\n",
        "colNames = [\"f\"+f'{i:03}' for i in range(1,n)]\n",
        "colNames.append('letter')\n",
        "#print(colNames)\n",
        "df.columns = colNames\n",
        "print(df['letter'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "262f3f53",
      "metadata": {
        "tags": [
          "mapLettersM"
        ]
      },
      "source": [
        "For the last column, map the letterIds (1..26) to lower case letters\n",
        "('a'..'z') and check that this mapping worked OK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98ca5d8f",
      "metadata": {
        "tags": [
          "mapLetters"
        ]
      },
      "outputs": [],
      "source": [
        "# Note that we use mapping from a dictionary to do this efficiently.\n",
        "numLetters = 26\n",
        "letterIds = list(range(1,numLetters+1))\n",
        "# See https://www.geeksforgeeks.org/alphabet-range-in-python/\n",
        "lc_letters = [chr(i) for i in range(ord('a'), ord('z') + 1)]\n",
        "# See https://stackoverflow.com/a/209854/1988855\n",
        "toLcLetters = dict(zip(letterIds, lc_letters))\n",
        "# See https://stackoverflow.com/a/41678874/1988855\n",
        "df['letter'] = df['letter'].map(toLcLetters)\n",
        "display(df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6998e12",
      "metadata": {
        "tags": [
          "intro2"
        ]
      },
      "source": [
        "## Reducing the dimensions before starting the visualisations\n",
        "\n",
        "We could use k-means partitional clustering on the (numeric-valued)\n",
        "audio data to derive 26 clusters. Hopefully each of these 26 clusters\n",
        "would be mostly made up of a single letter.\n",
        "However, this notebook focuses on visualising data subsets, so we will\n",
        "skip the clustering in this case and just use the assigned letters\n",
        "as labels for each set, and we will see how the subsets appear in visualisations\n",
        "obtained by\n",
        "1. Linear PCA to 2 dimensions\n",
        "2. t-SNE to 2 dimensions\n",
        "3. UMAP to 2 dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9afc81e",
      "metadata": {
        "tags": [
          "applyPCA1M"
        ]
      },
      "source": [
        "To reduce the computational requirements, especially for t-SNE, we will first\n",
        "apply linear PCA to reduce the dimensionality of the data from 617 columns.\n",
        "We will then use the resulting reduced data as input to each of the dimensionality reduction\n",
        "techniques, so they are comparable.\n",
        "In this first pass of PCA, we choose to keep `keepRatio` of the variance, and to drop\n",
        "the remaining components, reducing the dimensions from 617 to 32.\n",
        "Since the data was already scaled, we do not need to scale it again, as would normally\n",
        "be needed for applying PCA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9976c8a4",
      "metadata": {
        "tags": [
          "applyPCA1"
        ]
      },
      "outputs": [],
      "source": [
        "# Let the solver choose the number of components to keep, so that they capture\n",
        "# at least keepRatio of the original variance\n",
        "keepRatio = 0.8\n",
        "pca1=PCA(n_components=keepRatio, svd_solver='full')\n",
        "# See https://www.geeksforgeeks.org/select-all-columns-except-one-given-column-in-a-pandas-dataframe/\n",
        "# Note that drop() does not affect the original dataframe unless we add inplace=True\n",
        "pca1.fit(df.drop('letter', axis=1))\n",
        "nd_PCA1 = pca1.transform(df.drop('letter', axis=1))\n",
        "# Get the actual number of componwents directly from the object\n",
        "n_components_PCA1 = pca1.n_components_\n",
        "# Now derive df_PCA1 from the nd_PCA1 array, assigning suitable column names, using the default range index.\n",
        "columns_PCA1 = [f'pc{i}' for i in range(0,n_components_PCA1)]\n",
        "df_PCA1 = pd.DataFrame(data=nd_PCA1, columns=columns_PCA1)\n",
        "print(f'Number of rows is {m} and number of columns after {keepRatio} of variance is kept is {n_components_PCA1}\\n')\n",
        "display(df_PCA1.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e5b430f",
      "metadata": {
        "incorrectly_encoded_metadata": "tags=[scalingPCA1M\"]"
      },
      "source": [
        "## Normalise the scaling of df_PCA1\n",
        "\n",
        "Dimensionality reduction is affecting by scaling, so it is advisable to \n",
        "normalise the scaling of each column of the input dataframe df_PCA1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19e47cf1",
      "metadata": {
        "tags": [
          "scalingPCA1"
        ]
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "nd_PCA1 = scaler.fit_transform(df_PCA1.to_numpy())\n",
        "df_PCA1 = pd.DataFrame(data=nd_PCA1, columns=columns_PCA1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f30c7005",
      "metadata": {
        "tags": [
          "applyPCA2M"
        ]
      },
      "source": [
        "## Use PCA to further reduce to n_components = 2 dimensions, yielding df_PCA2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fec00db9",
      "metadata": {
        "tags": [
          "applyPCA2"
        ]
      },
      "outputs": [],
      "source": [
        "n_components = 2\n",
        "reducer = PCA(n_components=n_components)\n",
        "colPrefix = 'pc'\n",
        "df_PCA2, reducer = applyReducer(reducer, df_PCA1, colPrefix, n_components)\n",
        "explainedVarianceRatio = reducer.explained_variance_ratio_\n",
        "print(f'Number of rows is {m} and number of columns is {n_components} with explained variance ratio {explainedVarianceRatio}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9499c871",
      "metadata": {
        "tags": [
          "visualisePCA2M"
        ]
      },
      "source": [
        "## Visualise the 2-component PCA fit: df_PCA2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5cdff86",
      "metadata": {
        "tags": [
          "visualisePCA2"
        ]
      },
      "outputs": [],
      "source": [
        "visualiseReducedDim(df_PCA2, df['letter'], 'PCA')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5f44511",
      "metadata": {
        "tags": [
          "applyTSNEM"
        ]
      },
      "source": [
        "## Use TSNE to further reduce df_PCA1 to n_components = 2 dimensions, yielding df_TSNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7664aedd",
      "metadata": {
        "tags": [
          "applyTSNE"
        ]
      },
      "outputs": [],
      "source": [
        "perplexity=30\n",
        "print(f'Use t-SNE with perplexity {perplexity} to reduce the dimensions nonlinearly to {n_components}\\n')\n",
        "reducer = TSNE(n_components=n_components, learning_rate='auto', init='random', random_state = 42, perplexity=perplexity, verbose=1)\n",
        "colPrefix = 'tsne'\n",
        "df_TSNE, reducer = applyReducer(reducer, df_PCA1, colPrefix, n_components)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1a38349",
      "metadata": {
        "tags": [
          "visualiseTSNEM"
        ]
      },
      "source": [
        "## Visualise the 2-component TSNE fit: df_TSNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fed6f4cf",
      "metadata": {
        "tags": [
          "visualiseTSNE"
        ]
      },
      "outputs": [],
      "source": [
        "visualiseReducedDim(df_TSNE, df['letter'], 'TSNE')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6250c70f",
      "metadata": {
        "tags": [
          "applyUMAPM"
        ]
      },
      "source": [
        "## Use UMAP to further reduce df_PCA1 to n_components = 2 dimensions, yielding df_UMAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51c2a106",
      "metadata": {
        "tags": [
          "applyUMAP"
        ]
      },
      "outputs": [],
      "source": [
        "print(f'Use UMAP to reduce the dimensions nonlinearly to {n_components}\\n')\n",
        "reducer = umap.UMAP(n_components=n_components, random_state=42)\n",
        "colPrefix = 'umap'\n",
        "df_UMAP, reducer = applyReducer(reducer, df_PCA1, colPrefix, n_components)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70d9357b",
      "metadata": {
        "tags": [
          "visualiseUMAPM"
        ]
      },
      "source": [
        "## Visualise the 2-component UMAP fit: df_UMAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1a3d43c",
      "metadata": {
        "tags": [
          "visualiseUMAP"
        ]
      },
      "outputs": [],
      "source": [
        "visualiseReducedDim(df_UMAP, df['letter'], 'UMAP')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "164aba3d",
      "metadata": {
        "tags": [
          "Exercises"
        ]
      },
      "source": [
        "## Exercises\n",
        "\n",
        "1. Investigate the choice of the TSNE hyperparameters `perplexity`, `early_exaggeration` and `learning_rate`\n",
        "   and inspect the resulting plots to choose the best combination of these parameter settings.\n",
        "2. Investigate the choice of the UMAP hyperparameters `n_neighbors` and `min_dist` and inspect the resulting\n",
        "   the resulting plots to choose the best combination of these parameter settings. "
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}
