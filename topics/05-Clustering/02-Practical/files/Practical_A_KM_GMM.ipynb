{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "de180074",
      "metadata": {},
      "source": [
        "# Clustering generated data\n",
        "\n",
        "Clustering is easier when the clusters have a simple shape (hyperellipsoid, say)  and are well separated from each other.\n",
        "\n",
        "However, not all data has these characteristics. One data set that was chosen to be \"difficult\" was used to make the case for a new `hdbscan` clustering algorithm. This data set was published with the _Comparing Clustering Algorithms_ [page](https://hdbscan.readthedocs.io/en/latest/comparing_clustering_algorithms.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c37673cc",
      "metadata": {},
      "source": [
        "As usual, we import several libraries, including `csupport` which is a set of python functions that support the notebooks associated with week 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "159b1260",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn.cluster as cluster\n",
        "import time\n",
        "\n",
        "import sys\n",
        "#sys.path.append('../../20-resources/files/python')\n",
        "import clusSupport as cs\n",
        "\n",
        "dataDir = \"data\"\n",
        "# Make sure the outputDir subdirectory exists\n",
        "outputDir = \"output/Practical_A_GeneratedData\"\n",
        "import os, errno\n",
        "try:\n",
        "    os.makedirs(outputDir)\n",
        "except OSError as e:\n",
        "    if e.errno != errno.EEXIST:\n",
        "        raise\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c7cad11",
      "metadata": {},
      "source": [
        "Assign plot settings for seaborn and for matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c3f77e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set_context('poster')\n",
        "sns.set_color_codes()\n",
        "plot_kwds = {'alpha' : 0.25, 's' : 15, 'linewidths':0}\n",
        "paletteName = 'deep'\n",
        "fontSize = 10\n",
        "fc = '#cccccc'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99fa1387",
      "metadata": {},
      "source": [
        "Load existing data stored in NumPy's binary format. This data has complex features and is a major challenge for k-means, Gaussian Mixture Models and similar algorithms, although suitably tuned density-based clustering algorithms work reasonably well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "780b05b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = np.load(dataDir + '/complexDataForClustering.npy')\n",
        "data.T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d231750d",
      "metadata": {},
      "source": [
        "Generate a scatter plot of the two columns after transforming them to rows "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a7bc24e",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(data.T[0], data.T[1], c='b', **plot_kwds)\n",
        "frame = plt.gca()\n",
        "frame.axes.get_xaxis().set_visible(False)\n",
        "frame.axes.get_yaxis().set_visible(False)\n",
        "plt.savefig(outputDir + '/complexDataForClustering.pdf')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cb84e2f",
      "metadata": {},
      "source": [
        "As can be seen, the data has some areas where the points are closer together, but the boundaries are indistinct and the shapes are not simple shapes such as lines, circles or ellipses. It looks like there are _6_ clusters, so we set `n_clusters` = 6 below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7315012f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import cdist\n",
        "outFile = outputDir + '/kmeans6_generated.pdf'\n",
        "nClusters = 6\n",
        "clusterParams = {'n_clusters':nClusters, 'random_state':0}\n",
        "algName = \"KMeans\"\n",
        "\n",
        "start_time = time.time()\n",
        "kmeans = cluster.KMeans(**clusterParams)\n",
        "labels = kmeans.fit_predict(data)\n",
        "# Subsequently, this will be invoked using a function call of the form\n",
        "# kmeans, labels = w8s.fitClusterLabels(data, cluster.KMeans, (), clusterParams)\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time-start_time\n",
        "print(elapsed_time)\n",
        "\n",
        "title = '{} Clusters found by {}'.format(str(nClusters),algName)\n",
        "plt = cs.plot_2dClusters(data, labels, title, paletteName, fontSize, plot_kwds)\n",
        "outFile = outputDir + '/{}{}_generated.pdf'.format(algName,str(nClusters))\n",
        "plt.savefig(outFile)\n",
        "\n",
        "title = '{} Clusters (with regions) found by {}'.format(str(nClusters),algName)\n",
        "centres = kmeans.cluster_centers_\n",
        "radii = [cdist(data[labels == i], [center]).max()\n",
        "         for i, center in enumerate(centres)]\n",
        "plt = cs.overlayDisks(plt, centres, radii, fc, plot_kwds)\n",
        "outFile = outputDir + '/{}{}withCentres_generated.pdf'.format(algName,str(nClusters))\n",
        "plt.savefig(outFile)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4eb4c668",
      "metadata": {},
      "source": [
        "As might be expected, k-means does not do well wit this data set. Its features are not remotely circular, so k-means needs to create larger cluster \"regions\" that overlap. It is clearly not the best choice for this data.\n",
        "\n",
        "In some ways, k-means is a special case of a Gaussian Mixture model, in the sense that the latter can handle hyperellipsoidal features. So we try this model instead. We can make the Gaussian Mixtures model more like k-means by choosing a `'spherical'` covariance, or we can allow full flexibiltiy (ellipsoids with arbitrary orientation and eccentricity) by choosing the `'full'` covariance model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fa18f16",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sklearn.mixture as mixture\n",
        "\n",
        "algName = \"GaussianMixture\"\n",
        "for covType in ['spherical', 'full']:\n",
        "    clusterParams = {'n_components':6, 'covariance_type':covType, 'max_iter':100, 'random_state':0}\n",
        "    start_time = time.time()\n",
        "    gaussianMixture = mixture.GaussianMixture(**clusterParams)\n",
        "    #print(dir(gaussianMixture))\n",
        "    labels = gaussianMixture.fit(data).predict(data)\n",
        "    # Subsequently, this will be invoked using a function call of the form\n",
        "    # gaussianMixture, labels = w8s.fitClusterLabels(data, mixture.GaussianMixture, (), clusterParams)\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time-start_time\n",
        "    print(elapsed_time)\n",
        "    #plt, elapsed_time = w8s.plot_clusters(data, mixture.GaussianMixture, (), clusterParams, plot_kwds)\n",
        "    \n",
        "    plt.clf() # Start new plot\n",
        "    title = '{} Clusters found by {}'.format(str(nClusters),algName)\n",
        "    plt = cs.plot_2dClusters(data, labels, title, paletteName, fontSize, plot_kwds)\n",
        "    outFile = outputDir + '/{}{}_{}_generated.pdf'.format(algName,str(nClusters),covType)\n",
        "    plt.savefig(outFile)\n",
        "\n",
        "    title = '{} Clusters (with regions) found by {}'.format(str(nClusters),algName)\n",
        "    weights = gaussianMixture.weights_\n",
        "    means = gaussianMixture.means_\n",
        "    covariances = gaussianMixture.covariances_\n",
        "    plt = cs.overlayEllipses(plt, weights, means, covariances)\n",
        "    outFile = outputDir + '/{}{}_{}_withEllipses_generated.pdf'.format(algName,str(nClusters),covType)\n",
        "    plt.savefig(outFile)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b8de483",
      "metadata": {},
      "source": [
        "The Gaussian Mixture model, when allowed to vary the covariance, generally does better in the sense that it can match the geometric features in the data more faithfully than k-means. However, it is clear that there is still a lot of overlap (so the clusters are not distinguishable in this case).\n",
        "\n",
        "A completely different approach is the density-based approach followed by `DBSCAN`. This model takes a more relaxed interpretation of clusters - they are merely regions where the data is closer together. The \"shape\" of the cluster, its centre and other parameters are immaterial to its definition.\n",
        "\n",
        "With `DBSCAN`, the user specifies a (global) distance tolerance rather than the number of clusters. We note that it can be difficult to choose this tolerance, as it can be too large in some areas and too small in others. Indeed, the quality of any clustering can be very sensitive in respect of this setting. That said, `DBSCAN` clearly performs much better than its peers in respect of this data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec3851fa",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "algName = \"DBSCAN\"\n",
        "for eps in [0.01, 0.025, 0.05]:\n",
        "    clusterParams = {'eps':eps}\n",
        "    start_time = time.time()\n",
        "    dbscan = cluster.DBSCAN(**clusterParams)\n",
        "    labels = dbscan.fit_predict(data)\n",
        "    # Subsequently, this will be invoked using a function call of the form\n",
        "    # dbscan, labels = w8s.fitClusterLabels(data, cluster.DBSCAN, (), clusterParams)\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time-start_time\n",
        "    print(elapsed_time)\n",
        "    \n",
        "    plt.clf() # Start new plot\n",
        "    nClusters = len(set(labels))\n",
        "    title = '{} Clusters found by {} with eps={}'.format(str(nClusters),algName,str(eps).replace('.','p'))\n",
        "    plt = cs.plot_2dClusters(data, labels, title, paletteName, fontSize, plot_kwds)\n",
        "    outFile = outputDir + '/{}{}_{}_generated.pdf'.format(algName,str(nClusters),str(eps))\n",
        "    plt.savefig(outFile)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17e21ce3",
      "metadata": {},
      "source": [
        "As can be seen, `DBSCAN` starts to model \"noise\" when `eps` is too large. A more recent refinement of `DBSCAN` makes configuration much easier. `HDBSCAN` derives a hierarchical clustering and then uses the `min_cluster_size` setting to control how find the clustering should be. Generally, smaller cluster sizes are associated with more clusters. This setting is much more appealing than the distance threshold used by its parent `DBSCAN` algorithm. We try several options and see that, with the best setting, the clustering is srprisingly good and close to what would be considered a good clustering by human experts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d1e3e41",
      "metadata": {
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "import hdbscan\n",
        "algName = \"HDBSCAN\"\n",
        "for minClusterSize in [10, 15, 30]:\n",
        "    clusterParams = {'min_cluster_size':minClusterSize}\n",
        "    start_time = time.time()\n",
        "    hdbscanModel = hdbscan.HDBSCAN(**clusterParams)\n",
        "    labels = hdbscanModel.fit_predict(data)\n",
        "    # Subsequently, this will be invoked using a function call of the form\n",
        "    # hdbscan, labels = w8s.fitClusterLabels(data, hdbscan.HDBSCAN, (), clusterParams)\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time-start_time\n",
        "    print(elapsed_time)\n",
        "    \n",
        "    plt.clf() # Start new plot\n",
        "    nClusters = len(set(labels))\n",
        "    title = '{} Clusters found by {} minClusterSize={}'.format(str(nClusters),algName,str(minClusterSize))\n",
        "    plt = cs.plot_2dClusters(data, labels, title, paletteName, fontSize, plot_kwds)\n",
        "    outFile = outputDir + '/{}{}_{}_generated.pdf'.format(algName,str(nClusters),str(minClusterSize))\n",
        "    plt.savefig(outFile)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
