{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "56d39a1c",
      "metadata": {},
      "source": [
        "# TF-IDF applied to Inaugural Addresses using Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c97dded",
      "metadata": {},
      "source": [
        "This notebook is based on [TF-IDF with Scikit-Learn](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/03-TF-IDF-Scikit-Learn.html)\n",
        "\n",
        "We are going to calculate tf-idf scores using the Python library scikit-learn, which has a module called [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n",
        "\n",
        "We will apply this to calculate tf-idf scores for U.S. Inaugural Addresses."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6185e51",
      "metadata": {},
      "source": [
        "Import necessary modules and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a8aa49e",
      "metadata": {
        "tags": [
          "baseImports"
        ]
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d835314f",
      "metadata": {},
      "source": [
        "We are going to look for the \"interesting\" words in the inaugural speeches. In this case, we wish to see which president said what, so rather than using the NLTK corpus, we use [the same data from kaggle](https://www.kaggle.com/code/pabheeshta/us-presidential-inaugural-speeches).\n",
        "\n",
        "You should download this data and put it in a `data` folder below where you put this notebook. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28f91b80",
      "metadata": {
        "incorrectly_encoded_metadata": "tags={\"readSpeeches\"]"
      },
      "outputs": [],
      "source": [
        "speechDf = pd.read_csv('data/inaug_speeches.csv', usecols=['Name','Date','text'], encoding='latin1')\n",
        "speechDf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb87eb2e",
      "metadata": {},
      "source": [
        "We need to prepare the dataframe so that we can label each speech appropriately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15e1819b",
      "metadata": {
        "tags": [
          "addYear_Name"
        ]
      },
      "outputs": [],
      "source": [
        "speechDf['year'] = pd.DatetimeIndex(speechDf['Date']).year\n",
        "speechDf['year_Name'] = speechDf['year'].astype(str).str.cat(speechDf[['Name']], sep=\"_\")\n",
        "speechDf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df7dfb7c",
      "metadata": {},
      "source": [
        "## Calculate tf–idf\n",
        "\n",
        "To calculate tf–idf scores for every word, we're going to use scikit-learn's [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n",
        "\n",
        "When you initialize TfidfVectorizer, you can choose to set it with different parameters. These parameters will change the way you calculate tf–idf.\n",
        "\n",
        "The recommended way to run `TfidfVectorizer` is with smoothing (`smooth_idf = True`) and normalization (`norm='l2'`) turned on. These parameters will better account for differences in text length, and overall produce more meaningful tf–idf scores. Smoothing and L2 normalization are actually the default settings for `TfidfVectorizer`, so to turn them on, you don't need to include any extra code at all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "642ef2b1",
      "metadata": {
        "tags": [
          "tfidf_vectorizer"
        ]
      },
      "outputs": [],
      "source": [
        "# Initialize TfidfVectorizer with desired parameters (default\n",
        "# smoothing and normalization\n",
        "tfidf_vectorizer = TfidfVectorizer(input='content', stop_words='english')\n",
        "\n",
        "# Run TfidfVectorizer on the text in speechDf.\n",
        "tfidf_vector = tfidf_vectorizer.fit_transform(speechDf[\"text\"])\n",
        "\n",
        "# Make a DataFrame out of the resulting tf-idf vector, setting the\n",
        "# \"feature names\" or words as columns and the titles as rows\n",
        "tfidf_df = pd.DataFrame(tfidf_vector.toarray(), index=speechDf['year_Name'],\n",
        "  columns=tfidf_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1918fd71",
      "metadata": {},
      "source": [
        "Add column for document frequency aka number of times word appears in all documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02e35c6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf_df.loc['00_Document Frequency'] = (tfidf_df > 0).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00a25a98",
      "metadata": {
        "tags": [
          "tfidf_slice"
        ]
      },
      "outputs": [],
      "source": [
        "tfidf_slice = tfidf_df[['government', 'borders', 'people', 'obama', 'war', 'honor','foreign', 'men', 'women', 'children']]\n",
        "tfidf_slice.sort_index().round(decimals=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ada398ed",
      "metadata": {},
      "source": [
        "Let's drop \"OO_Document Frequency\" since we were just using it for illustration purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a841e83",
      "metadata": {
        "tags": [
          "tfidf_df1"
        ]
      },
      "outputs": [],
      "source": [
        "tfidf_df = tfidf_df.drop('00_Document Frequency', errors='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78b1ec32",
      "metadata": {},
      "source": [
        "Let's reorganize the DataFrame so that the words are in rows rather than columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ab6757d",
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf_df.stack().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7372d48e",
      "metadata": {
        "tags": [
          "tfidf_df2"
        ]
      },
      "outputs": [],
      "source": [
        "tfidf_df = tfidf_df.stack().reset_index()\n",
        "tfidf_df = tfidf_df.rename(columns={0:'tfidf', 'level_0': 'year_Name','level_1': 'term', 'level_2': 'term'})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22708229",
      "metadata": {},
      "source": [
        "To find out the top 10 words with the highest tf–idf for every story, we're going to sort by document and tfidf score and then groupby year_Name and take the first 10 values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73fe9198",
      "metadata": {
        "tags": [
          "output_scroll"
        ]
      },
      "outputs": [],
      "source": [
        "tfidf_df.sort_values(by=['year_Name','tfidf'], ascending=[True,False]).groupby(['year_Name']).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa3d36cf",
      "metadata": {
        "tage": [
          "top_tfidf"
        ]
      },
      "outputs": [],
      "source": [
        "top_tfidf = tfidf_df.sort_values(by=['year_Name','tfidf'], ascending=[True,False]).groupby(['year_Name']).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2c6768a",
      "metadata": {},
      "source": [
        "We can zoom in on particular words and particular documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a67cbb5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "top_tfidf[top_tfidf['term'].str.contains('women')]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8be6b53",
      "metadata": {},
      "source": [
        "It turns out that the term \"women\" is very distinctive in Obama's Inaugural Address."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d45c8bcb",
      "metadata": {
        "tags": [
          "topObama"
        ]
      },
      "outputs": [],
      "source": [
        "top_tfidf[top_tfidf['year_Name'].str.contains('Obama')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d50a060",
      "metadata": {
        "tags": [
          "topTrump"
        ]
      },
      "outputs": [],
      "source": [
        "top_tfidf[top_tfidf['year_Name'].str.contains('Trump')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a654cee4",
      "metadata": {
        "tags": [
          "topKennedy"
        ]
      },
      "outputs": [],
      "source": [
        "top_tfidf[top_tfidf['year_Name'].str.contains('Kennedy')]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca7ee5ae",
      "metadata": {},
      "source": [
        "## Visualize TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beb9e0d7",
      "metadata": {},
      "source": [
        "We can also visualize our TF-IDF results with the data visualization library Altair, which needs to be installed using\n",
        "\n",
        "    conda install -c conda-forge altair"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "620775cb",
      "metadata": {},
      "source": [
        "Let's make a heatmap that shows the highest TF-IDF scoring words for each president, and let's put a red dot next to two terms of interest: \"war\" and \"peace\":\n",
        "\n",
        "The code below was contributed by [Eric Monson](https://github.com/emonson). Thanks, Eric!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b481af68",
      "metadata": {
        "tags": [
          "visualiseHeatmap"
        ]
      },
      "outputs": [],
      "source": [
        "import altair as alt\n",
        "import numpy as np\n",
        "\n",
        "# Terms in this list will get a red dot in the visualization\n",
        "term_list = ['war', 'peace']\n",
        "\n",
        "# adding a little randomness to break ties in term ranking\n",
        "top_tfidf_plusRand = top_tfidf.copy()\n",
        "top_tfidf_plusRand['tfidf'] = top_tfidf_plusRand['tfidf'] + np.random.rand(top_tfidf.shape[0])*0.0001\n",
        "\n",
        "# base for all visualizations, with rank calculation\n",
        "base = alt.Chart(top_tfidf_plusRand).encode(\n",
        "    x = 'rank:O',\n",
        "    y = 'year_Name:N'\n",
        ").transform_window(\n",
        "    rank = \"rank()\",\n",
        "    sort = [alt.SortField(\"tfidf\", order=\"descending\")],\n",
        "    groupby = [\"year_Name\"],\n",
        ")\n",
        "\n",
        "# heatmap specification\n",
        "heatmap = base.mark_rect().encode(\n",
        "    color = 'tfidf:Q'\n",
        ")\n",
        "\n",
        "# red circle over terms in above list\n",
        "circle = base.mark_circle(size=100).encode(\n",
        "    color = alt.condition(\n",
        "        alt.FieldOneOfPredicate(field='term', oneOf=term_list),\n",
        "        alt.value('red'),\n",
        "        alt.value('#FFFFFF00')        \n",
        "    )\n",
        ")\n",
        "\n",
        "# text labels, white for darker heatmap colors\n",
        "text = base.mark_text(baseline='middle').encode(\n",
        "    text = 'term:N',\n",
        "    color = alt.condition(alt.datum.tfidf >= 0.23, alt.value('white'), alt.value('black'))\n",
        ")\n",
        "\n",
        "# display the three superimposed visualizations\n",
        "(heatmap + circle + text).properties(width = 600)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
