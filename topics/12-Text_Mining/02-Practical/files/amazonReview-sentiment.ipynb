{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "83ef8bc8",
      "metadata": {},
      "source": [
        "# Sentiment Analysis of Amazon Reviews\n",
        "\n",
        "In this notebook we will be doing some sentiment analysis in python using two different techniques:\n",
        "1. VADER (Valence Aware Dictionary and sEntiment Reasoner) - Bag of words approach\n",
        "2. Roberta Pretrained Model from ðŸ¤—\n",
        "\n",
        "As a bonus, we show how the analysis can be moved to a HuggingFace pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a29111b",
      "metadata": {},
      "source": [
        "## Step 0. Read in Data and NLTK Basics\n",
        "\n",
        "Note that we also need to choose a lexicon of words for the bag of words model. Usually it is better to chooise a lexicon of words that are specific to the domain, but here we use a generic lexicon. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "633a8775",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "import nltk\n",
        "# The following downloads need to be performed just once.\n",
        "# They can be commented out afterwards.\n",
        "#nltk.downloader.download('vader_lexicon')\n",
        "#nltk.download('averaged_perceptron_tagger_eng')\n",
        "#nltk.download('maxent_ne_chunker_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f111abeb",
      "metadata": {},
      "source": [
        "We read in the data, which comes from Amazon reviews of fine/up-market food products. We have selected the first 999 such reviews for convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65e1dd0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/Reviews1000.csv')\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cae9f7c",
      "metadata": {},
      "source": [
        "### EDA\n",
        "\n",
        "We now perform some limited EDA on the reviews. We are interested in the number of reviews by starr rating (1 to 5 stars)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58b2bac4",
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = df['Score'].value_counts().sort_index() \\\n",
        "    .plot(kind='bar',\n",
        "          title='Count of Reviews by Stars',\n",
        "          figsize=(10, 5))\n",
        "ax.set_xlabel('Review Stars')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfca4ca5",
      "metadata": {},
      "source": [
        "## Text processing using NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aff1e48e",
      "metadata": {},
      "outputs": [],
      "source": [
        "example = df['Text'][100]\n",
        "print(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a4d377e",
      "metadata": {},
      "outputs": [],
      "source": [
        "tokens = nltk.word_tokenize(example)\n",
        "tokens[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9720ff6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "tagged = nltk.pos_tag(tokens)\n",
        "tagged[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03f00e88",
      "metadata": {},
      "outputs": [],
      "source": [
        "entities = nltk.chunk.ne_chunk(tagged)\n",
        "entities.pprint()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "635fc3e2",
      "metadata": {},
      "source": [
        "## Step 1. VADER Sentiment Scoring\n",
        "\n",
        "We use NLTK's `SentimentIntensityAnalyzer` to get the neg/neu/pos scores of the text using VADER.\n",
        "\n",
        "- This uses a \"bag of words\" approach:\n",
        "    1. Stop words are removed\n",
        "    2. each word is scored and combined to a total score.\n",
        " \n",
        "The `SentimentInstensityAnalyzer` uses the bag of words from the standard lexicon (not specific to food reviews)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b525079",
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b02e8d6",
      "metadata": {},
      "source": [
        "We give it what might be considered a positive statement, but VADER decides it is only neutral. That is because the meaning of \"passed\" (in the sense of passing an exam) is missed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25fd6c93",
      "metadata": {},
      "outputs": [],
      "source": [
        "stmt = 'The exam results are in, and she passed.'\n",
        "sia.polarity_scores(stmt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce08c33d",
      "metadata": {},
      "source": [
        "Even when the sentiment is more clearly negative, VADER is agaiun confused, probably because the statement is about Trump but is not clearly the writer's belief."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99a6d4ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "stmt = 'Trump was the worst President in recent history.'\n",
        "sia.polarity_scores(stmt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b1792cc",
      "metadata": {},
      "source": [
        "The food review  regarding the apples is somewhat unclear - it has a positive (but indirect) Shakespearean quotation and comment implying dissatisfaction with the price. Deciding the review is neutral is probably the right interpretation here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bc44162",
      "metadata": {},
      "outputs": [],
      "source": [
        "sia.polarity_scores(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "098748a9",
      "metadata": {},
      "source": [
        "Now we can run the sentiment analyser over the entire dataset, adding the estimated sentiment as a new dict.\n",
        "\n",
        "Note the use of `tqdm` to provide a progress bar as the code works through the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79374930",
      "metadata": {},
      "outputs": [],
      "source": [
        "res = {}\n",
        "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    text = row['Text']\n",
        "    myid = row['Id']\n",
        "    res[myid] = sia.polarity_scores(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d26e2f7",
      "metadata": {},
      "source": [
        "Now we add the sentiment score array to the data, as an additional column, saving the combination in a new dataframe called `vaders`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fa8b806",
      "metadata": {},
      "outputs": [],
      "source": [
        "vaders = pd.DataFrame(res).T\n",
        "vaders = vaders.reset_index().rename(columns={'index': 'Id'})\n",
        "vaders = vaders.merge(df, how='left')\n",
        "vaders.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efecd93b",
      "metadata": {},
      "source": [
        "## Plot VADER results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ff5a1fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = sns.barplot(data=vaders, x='Score', y='compound')\n",
        "ax.set_title('Compound Score by Amazon Star Review')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1715878",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(12, 3))\n",
        "sns.barplot(data=vaders, x='Score', y='pos', ax=axs[0])\n",
        "sns.barplot(data=vaders, x='Score', y='neu', ax=axs[1])\n",
        "sns.barplot(data=vaders, x='Score', y='neg', ax=axs[2])\n",
        "axs[0].set_title('Positive')\n",
        "axs[1].set_title('Neutral')\n",
        "axs[2].set_title('Negative')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a535f4e",
      "metadata": {},
      "source": [
        "# Step 3. Roberta Pretrained Model\n",
        "\n",
        "- Use a model trained of a large corpus of data.\n",
        "- Transformer model accounts for the words but also the context related to other words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d78bb024",
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from scipy.special import softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2bdfaeb",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd41cb63",
      "metadata": {},
      "outputs": [],
      "source": [
        "# VADER results on example\n",
        "print(example)\n",
        "sia.polarity_scores(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0e62542",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run for Roberta Model\n",
        "encoded_text = tokenizer(example, return_tensors='pt')\n",
        "output = model(**encoded_text)\n",
        "scores = output[0][0].detach().numpy()\n",
        "scores = softmax(scores)\n",
        "scores_dict = {\n",
        "    'roberta_neg' : scores[0],\n",
        "    'roberta_neu' : scores[1],\n",
        "    'roberta_pos' : scores[2]\n",
        "}\n",
        "print(scores_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b86db224",
      "metadata": {},
      "outputs": [],
      "source": [
        "def polarity_scores_roberta(example):\n",
        "    encoded_text = tokenizer(example, return_tensors='pt')\n",
        "    output = model(**encoded_text)\n",
        "    scores = output[0][0].detach().numpy()\n",
        "    scores = softmax(scores)\n",
        "    scores_dict = {\n",
        "        'roberta_neg' : scores[0],\n",
        "        'roberta_neu' : scores[1],\n",
        "        'roberta_pos' : scores[2]\n",
        "    }\n",
        "    return scores_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7ed3f7c",
      "metadata": {},
      "outputs": [],
      "source": [
        "res = {}\n",
        "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    try:\n",
        "        text = row['Text']\n",
        "        myid = row['Id']\n",
        "        vader_result = sia.polarity_scores(text)\n",
        "        vader_result_rename = {}\n",
        "        for key, value in vader_result.items():\n",
        "            vader_result_rename[f\"vader_{key}\"] = value\n",
        "        roberta_result = polarity_scores_roberta(text)\n",
        "        both = {**vader_result_rename, **roberta_result}\n",
        "        res[myid] = both\n",
        "    except RuntimeError:\n",
        "        print(f'Broke for id {myid}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b5e7b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(res).T\n",
        "results_df = results_df.reset_index().rename(columns={'index': 'Id'})\n",
        "results_df = results_df.merge(df, how='left')\n",
        "results_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "833e7007",
      "metadata": {},
      "source": [
        "## Compare Scores between models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff647723",
      "metadata": {},
      "source": [
        "# Step 3. Combine and compare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd3a51ce",
      "metadata": {
        "incorrectly_encoded_metadata": "tags=[VaderRobertaPairplot\"]"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(data=results_df,\n",
        "             vars=['vader_neg', 'vader_neu', 'vader_pos',\n",
        "                  'roberta_neg', 'roberta_neu', 'roberta_pos'],\n",
        "            hue='Score',\n",
        "            palette='tab10')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb20b7a9",
      "metadata": {},
      "source": [
        "# Step 4: Review Examples:\n",
        "\n",
        "- Positive 1-Star and Negative 5-Star Reviews\n",
        "\n",
        "Lets look at some examples where the model scoring and review score differ the most."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee7a8689",
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df.query('Score == 1') \\\n",
        "    .sort_values('roberta_pos', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce239f6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df.query('Score == 1') \\\n",
        "    .sort_values('vader_pos', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "693acd8d",
      "metadata": {},
      "source": [
        "Negative sentiment 5-Star view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1210e38c",
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df.query('Score == 5') \\\n",
        "    .sort_values('roberta_neg', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37125988",
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df.query('Score == 5') \\\n",
        "    .sort_values('vader_neg', ascending=False)['Text'].values[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f2e7fbb",
      "metadata": {},
      "source": [
        "# Extra: The Transformers Pipeline\n",
        "- Quick & easy way to run sentiment predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45b7ebc9",
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "pipelineType = \"sentiment-analysis\"\n",
        "sent_pipeline = pipeline(pipelineType)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "185ce26d",
      "metadata": {},
      "outputs": [],
      "source": [
        "sent_pipeline('I love good weather')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92f83adb",
      "metadata": {},
      "outputs": [],
      "source": [
        "sent_pipeline('The hotel is not too bad.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51ae7ee8",
      "metadata": {},
      "outputs": [],
      "source": [
        "sent_pipeline('The song is terrible.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f7246f1",
      "metadata": {},
      "source": [
        "# The End"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51ff2c1e",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
